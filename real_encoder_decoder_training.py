# -*- coding: utf-8 -*-
"""real_encoder_decoder_training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14fl3a3vfstKJDkzXLNXungbVcMa29P8u

#Init
"""
import json

import gensim

"""# Imports"""
import tensorflow
from tensorflow.keras.utils import plot_model
from tensorflow import keras
from tensorflow.keras.layers import (LSTM,
                                     Bidirectional,
                                     CuDNNGRU,
                                     CuDNNLSTM,
                                     Dense,
                                     Embedding,
                                     Input,
                                     TimeDistributed,
                                     Concatenate,
                                     Multiply,
                                     Activation,
                                     Flatten,
                                     Convolution1D,
                                     Dropout,
                                     BatchNormalization)
from tensorflow.keras.models import load_model as lm
import numpy as np
from pprint import pprint as pr
import re
import nltk

import random
from abc import ABCMeta, abstractmethod

"""# Classes definitions"""


class EncoderDecoder(metaclass=ABCMeta):
    """
  Class implementation for the encoder decoder architecture
  """

    def __init__(self, kwargs):
        for k in kwargs:
            self.__dict__[k] = kwargs[k]
        """
      Must provide a dictionary containing the following keys/values :
      {_
          'model_name': 'base',
          'encoder_input_dim': vector_size+postag_vec_size,
          'encoder_output_dim': 64,
          'encoder_dense_units': 64,
          'encoder_dense_output_dim' :n_intents,
          'decoder_input_dim': n_tags,
          'decoder_output_dim': n_tags,
      }
      """
        self.id = random.randint(0, 155)
        self._build_model()

    @abstractmethod
    def _build_model(self):
        pass

    def predict_sequence(self, source, n_steps):
        # encode
        state = self.inf_encoder_model.predict(source)
        intent_output = self.inf_intent_classifier.predict(source)
        # start of sequence input
        target_seq = np.zeros(shape=(1, 1, self.decoder_input_dim))
        # collect predictions
        output = list()
        for t in range(n_steps):
            # predict next char
            yhat, h, c = self.inf_decoder_model.predict([target_seq] + state)
            # store prediction
            output.append(yhat[0, 0, :])
            # update state
            state = [h, c]
            # update target sequence
            target_seq = yhat
        return np.array(output), np.array(intent_output)

    @staticmethod
    def predict_sequence_static(top_model, source, n_steps):
        # encode
        state = top_model.inf_encoder_model.predict(source)
        intent_output = top_model.inf_intent_classifier.predict(source)
        # start of sequence input
        target_seq = np.zeros(shape=(1, 1, top_model.decoder_input_dim))
        # collect predictions
        output = list()
        for t in range(n_steps):
            # predict next char
            yhat, h, c = top_model.inf_decoder_model.predict([target_seq] + state)
            print('yhat is {}'.format(yhat.shape))
            # store prediction
            output.append(yhat[0, 0, :])
            # update state
            state = [h, c]
            # update target sequence
            target_seq = yhat
        return np.array(output), np.array(intent_output)

    def save_model_image(self):
        if self.model is None:
            print('[ERROR] Model is not defined')
            return
        plot_model(self.model, to_file='./{}.png'.format(self.model_name),
                   show_shapes=True, show_layer_names=True)

    @staticmethod
    def save_model_image_static(top_model):
        if top_model.model is None:
            print('[ERROR] Model is not defined')
            return
        plot_model(top_model.model, to_file='./{}.png'.format(top_model.model_name),
                   show_shapes=True, show_layer_names=True)

    def save_models_to_disk(self, root):
        self.model.save(root + '{}.h5'.format(self.model_name))
        self.inf_encoder_model.save(
            root + '{}_inf_encoder.h5'.format(self.model_name))
        self.inf_intent_classifier.save(
            root + '{}_inf_intent.h5'.format(self.model_name))
        self.inf_decoder_model.save(
            root + '{}_inf_decoder.h5'.format(self.model_name))

    @staticmethod
    def save_models_to_disk_static(top_model, root):
        top_model.model.save(root + '{}.h5'.format(top_model.model_name))
        top_model.inf_encoder_model.save(
            root + '{}_inf_encoder.h5'.format(top_model.model_name))
        top_model.inf_intent_classifier.save(
            root + '{}_inf_intent.h5'.format(top_model.model_name))
        top_model.inf_decoder_model.save(
            root + '{}_inf_decoder.h5'.format(top_model.model_name))

    def load_models_from_disk(self, root, new_name):
        self.model = lm(root + '{}.h5'.format(new_name))
        self.inf_encoder_model = lm(
            root + '{}_inf_encoder.h5'.format(new_name))
        self.inf_intent_classifier = lm(
            root + '{}_inf_intent.h5'.format(new_name))
        self.inf_decoder_model = lm(
            root + '{}_inf_decoder.h5'.format(new_name))

    def make_predict_functions(self):
        # self.model._make_predict_function()
        self.inf_decoder_model._make_predict_function()
        self.inf_encoder_model._make_predict_function()
        self.inf_intent_classifier._make_predict_function()

    def load_models_weights(self, root, new_name):
        self.model.load_weights(root + '{}.h5'.format(new_name))
        self.inf_encoder_model.load_weights(
            root + '{}_inf_encoder.h5'.format(new_name))
        self.inf_intent_classifier.load_weights(
            root + '{}_inf_intent.h5'.format(new_name))
        self.inf_decoder_model.load_weights(
            root + '{}_inf_decoder.h5'.format(new_name))

    @staticmethod
    def save_models_to_disk_static(top_model, root, new_name):
        top_model.model = lm(root + '{}.h5'.format(new_name))
        top_model.inf_encoder_model = lm(
            root + '{}_inf_encoder.h5'.format(new_name))
        top_model.inf_intent_classifier = lm(
            root + '{}_inf_intent.h5'.format(new_name))
        top_model.inf_decoder_model = lm(
            root + '{}_inf_decoder.h5'.format(new_name))


class EncoderDecoderBiLSTM(EncoderDecoder):
    def __init__(self, kwargs):
        EncoderDecoder.__init__(self, kwargs)

    def _build_model(self):
        """
      Helper function to build the layers of the model
      """
        # Define training encoder
        encoder_inputs = Input(shape=(None, self.encoder_input_dim),
                               name='encoder_inputs')
        # Creating the LSTM cell
        encoder_lstm = CuDNNLSTM(self.encoder_output_dim,
                                 return_state=True,
                                 return_sequences=False,
                                 name='encoder_lstm')
        # Wrapping it into a bidirectionnal layer
        encoder_bilstm = Bidirectional(encoder_lstm, merge_mode='concat')
        # The bidirectional wraper returns 5 variables
        encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(
            encoder_inputs)
        # We concatenate the left/right context of both
        state_h = Concatenate()([forward_h, backward_h])
        state_c = Concatenate()([forward_c, backward_c])
        # And save the hidden and internal states
        encoder_states = [state_h, state_c]
        # Define the dense output layer for the intent classification
        x = Dense(self.encoder_dense_units,
                  activation=self.activation,
                  name='encoder_hidden_dense_1', )(encoder_outputs)
        encoder_dense = Dense(self.encoder_dense_output_dim,
                              activation='softmax',
                              name='intent_classifier')
        # This layer will classify the intent
        intent_output = encoder_dense(x)

        returned = [encoder_inputs, intent_output, encoder_states]

        # Define training decoder
        decoder_inputs = Input(shape=(None, self.decoder_input_dim),
                               name='decoder_inputs')

        decoder_lstm = CuDNNLSTM(2 * self.encoder_output_dim,
                                 return_state=True,
                                 return_sequences=True,
                                 name='decoder_lstm')

        decoder_outputs, _, _ = decoder_lstm(decoder_inputs,
                                             initial_state=encoder_states)
        decoder_dense = Dense(self.decoder_output_dim,
                              activation='softmax',
                              name='named_entity_recognition')

        decoder_outputs = TimeDistributed(decoder_dense, name='named_entity_recognition')(decoder_outputs)
        returned = [decoder_inputs, decoder_outputs]
        # The traning model
        self.model = keras.Model(inputs=[encoder_inputs, decoder_inputs],
                                 outputs=[intent_output, decoder_outputs],
                                 name=self.model_name)

        # define inference_intent_classifier
        self.inf_intent_classifier = keras.Model(encoder_inputs, intent_output)
        # define inference encoder
        self.inf_encoder_model = keras.Model(encoder_inputs, encoder_states)
        # define inference decoder
        decoder_state_input_h = Input(shape=(2 * self.encoder_output_dim,))
        decoder_state_input_c = Input(shape=(2 * self.encoder_output_dim,))
        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]

        decoder_outputs, state_h, state_c = decoder_lstm(
            decoder_inputs, initial_state=decoder_states_inputs)

        decoder_states = [state_h, state_c]

        decoder_outputs = TimeDistributed(decoder_dense)(decoder_outputs)
        self.inf_decoder_model = keras.Model(
            [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)

    def __str__(self):
        return 'EncoderDecoderBiLSTM'

    @staticmethod
    def type():
        return 'EncoderDecoderBiLSTM'


class EncoderDecoderCpuBiLSTM(EncoderDecoder):
    def __init__(self, kwargs):
        EncoderDecoder.__init__(self, kwargs)

    def _build_model(self):
        """
      Helper function to build the layers of the model
      """
        # Define training encoder
        encoder_inputs = Input(shape=(None, self.encoder_input_dim),
                               name='encoder_inputs')
        # Creating the LSTM cell
        encoder_lstm = LSTM(self.encoder_output_dim,
                            return_state=True,
                            return_sequences=False,
                            name='encoder_lstm')
        # Wrapping it into a bidirectionnal layer
        encoder_bilstm = Bidirectional(encoder_lstm, merge_mode='concat')
        # The bidirectional wraper returns 5 variables
        encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(
            encoder_inputs)
        # We concatenate the left/right context of both
        state_h = Concatenate()([forward_h, backward_h])
        state_c = Concatenate()([forward_c, backward_c])
        # And save the hidden and internal states
        encoder_states = [state_h, state_c]
        # Define the dense output layer for the intent classification
        x = Dense(self.encoder_dense_units,
                  activation=self.activation,
                  name='encoder_hidden_dense_1', )(encoder_outputs)
        encoder_dense = Dense(self.encoder_dense_output_dim,
                              activation='softmax',
                              name='intent_classifier')
        # This layer will classify the intent
        intent_output = encoder_dense(x)

        returned = [encoder_inputs, intent_output, encoder_states]

        # Define training decoder
        decoder_inputs = Input(shape=(None, self.decoder_input_dim),
                               name='decoder_inputs')

        decoder_lstm = LSTM(2 * self.encoder_output_dim,
                            return_state=True,
                            return_sequences=True,
                            name='decoder_lstm')

        decoder_outputs, _, _ = decoder_lstm(decoder_inputs,
                                             initial_state=encoder_states)
        decoder_dense = Dense(self.decoder_output_dim,
                              activation='softmax',
                              name='named_entity_recognition')

        decoder_outputs = TimeDistributed(decoder_dense, name='named_entity_recognition')(decoder_outputs)
        returned = [decoder_inputs, decoder_outputs]
        # The traning model
        self.model = keras.Model(inputs=[encoder_inputs, decoder_inputs],
                                 outputs=[intent_output, decoder_outputs],
                                 name=self.model_name)

        # define inference_intent_classifier
        self.inf_intent_classifier = keras.Model(encoder_inputs, intent_output)
        # define inference encoder
        self.inf_encoder_model = keras.Model(encoder_inputs, encoder_states)
        # define inference decoder
        decoder_state_input_h = Input(shape=(2 * self.encoder_output_dim,))
        decoder_state_input_c = Input(shape=(2 * self.encoder_output_dim,))
        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]

        decoder_outputs, state_h, state_c = decoder_lstm(
            decoder_inputs, initial_state=decoder_states_inputs)

        decoder_states = [state_h, state_c]

        decoder_outputs = TimeDistributed(decoder_dense)(decoder_outputs)
        self.inf_decoder_model = keras.Model(
            [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)

    def __str__(self):
        return 'EncoderDecoderCpuBiLSTM'

    @staticmethod
    def type():
        return 'EncoderDecoderCpuBiLSTM'


class EncoderDecoderLSTM(EncoderDecoder):
    def __init__(self, kwargs):
        EncoderDecoder.__init__(self, kwargs)

    def _build_model(self):
        """
      Helper function to build the layers of the model
      """
        # Define training encoder
        encoder_inputs = Input(shape=(None, self.encoder_input_dim),
                               name='encoder_inputs')
        # Creating the LSTM cell
        encoder_lstm = CuDNNLSTM(self.encoder_output_dim,
                                 return_state=True,
                                 return_sequences=False,
                                 name='encoder_lstm')
        # Wrapping it into a bidirectionnal layer
        # The bidirectional wraper returns 5 variables
        encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)
        encoder_states = [state_h, state_c]
        # Define the dense output layer for the intent classification
        x = Dense(self.encoder_dense_units,
                  activation='relu',
                  name='encoder_hidden_dense_1', )(encoder_outputs)
        encoder_dense = Dense(self.encoder_dense_output_dim,
                              activation='softmax',
                              name='intent_classifier')
        # This layer will classify the intent
        intent_output = encoder_dense(x)

        returned = [encoder_inputs, intent_output, encoder_states]

        # Define training decoder
        decoder_inputs = Input(shape=(None, self.decoder_input_dim),
                               name='decoder_inputs')

        decoder_lstm = CuDNNLSTM(self.encoder_output_dim,
                                 return_state=True,
                                 return_sequences=True,
                                 name='decoder_lstm')

        decoder_outputs, _, _ = decoder_lstm(decoder_inputs,
                                             initial_state=encoder_states)
        decoder_dense = Dense(self.decoder_output_dim,
                              activation='softmax',
                              name='named_entity_recognition')

        decoder_outputs = TimeDistributed(decoder_dense, name='named_entity_recognition')(decoder_outputs)
        returned = [decoder_inputs, decoder_outputs]

        # The traning model
        self.model = keras.Model(inputs=[encoder_inputs, decoder_inputs],
                                 outputs=[intent_output, decoder_outputs],
                                 name=self.model_name)

        # define inference_intent_classifier
        self.inf_intent_classifier = keras.Model(encoder_inputs, intent_output)
        # define inference encoder
        self.inf_encoder_model = keras.Model(encoder_inputs, encoder_states)
        # define inference decoder
        decoder_state_input_h = Input(shape=(self.encoder_output_dim,))
        decoder_state_input_c = Input(shape=(self.encoder_output_dim,))
        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]

        decoder_outputs, state_h, state_c = decoder_lstm(
            decoder_inputs, initial_state=decoder_states_inputs)

        decoder_states = [state_h, state_c]

        decoder_outputs = TimeDistributed(decoder_dense)(decoder_outputs)
        self.inf_decoder_model = keras.Model(
            [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)

    def __str__(self):
        return 'EncoderDecoderLSTM'

    @staticmethod
    def type():
        return 'EncoderDecoderLSTM'


def n_words(data):
    types = [typ for typ in data['train_dataset']]
    res = set()
    for typ in types:
        for instance in data['train_dataset'][typ]:
            text = re.sub(r'{(.+?):}', '', instance['text'])
            res = res | set(text.split())
    return res


def create_postag_oh_dict(postag_set):
    n_features = len(postag_set)
    res = {tag: [1 if i == index else 0 for i in range(
        n_features)] for index, tag in enumerate(postag_set)}
    return res


def create_intent_oh_dict(intents_set):
    n_features = len(intents_set)
    res = {intent: [1 if i == index else 0 for i in range(
        n_features)] for index, intent in enumerate(intents_set)}
    return res


def create_tag_oh_dict(tags_set):
    n_features = len(tags_set)
    res = {intent: [1 if i == index else 0 for i in range(
        n_features)] for index, intent in enumerate(tags_set)}
    return res


def create_index_to_intent(intents_set):
    res = {index: tag for index, tag in enumerate(intents_set)}
    return res


def create_index_to_tag(tags_set):
    res = {index: tag for index, tag in enumerate(tags_set)}
    return res


def w2v(word, model):
    res = np.zeros(model.vector_size)
    if (word == '\start'):
        res[0] = 1
        return res
    if (word == '\end'):
        res[-1] = 1
        return res
    try:
        res = model[word]
    except Exception as e:
        res = model['UNK']
    return res


"""# Sets"""

TAGS_SET = [
    "alter.file_name",
    "exch.file_name",
    "info.file_name",
    "alter.directory_name",
    "exch.directory_name",
    "alter.parent_directory",
    "exch.parent_directory",
    "info.parent_directory",
    "new_directory",
    "origin",
    "dest",
    "old_name",
    "new_name",
    "NUL"
]

POSTAG_SET = {
    "''": 'Unknown',
    "$": 'Unknown',
    "(": 'Unknown',
    ")": 'Unknown',
    ":": 'Unknown',
    'PAD': 'padding tag for training in many batches',
    "#" : 'Number',
    '.': 'Punctuation',
    'CC': 'coordinating conjunction',
    'CD': 'cardinal digit',
    'DT': 'determiner',
    'EX': 'existential there (like: \"there is\" ... think of it like \"there exists\")',
    'FW': 'foreign word',
    'IN': 'preposition/subordinating conjunction',
    'JJ': 'adjective \'big\'',
    'JJR': 'adjective, comparative \'bigger\'',
    'JJS': 'adjective, superlative \'biggest\'',
    'LS': 'list marker 1)',
    'MD': 'modal could, will',
    'NN': 'noun, singular \'desk\'',
    'NNS': 'noun plural \'desks\'',
    'NNP': 'proper noun, singular \'Harrison\'',
    'NNPS': 'proper noun, plural \'Americans\'',
    'PDT': 'predeterminer \'all the kids\'',
    'POS': 'possessive ending parent\'s',
    'PRP': 'personal pronoun I, he, she',
    'PRP$': 'possessive pronoun my, his, hers',
    'RB': 'adverb very, silently,',
    'RBR': 'adverb, comparative better',
    'RBS': 'adverb, superlative best',
    'RP': 'particle give up',
    'TO': 'to go \'to\' the store.',
    'UH': 'interjection errrrrrrrm',
    'VB': 'verb, base form take',
    'VBD': 'verb, past tense took',
    'VBG': 'verb, gerund/present participle taking',
    'VBN': 'verb, past participle taken',
    'VBP': 'verb, sing. present, non-3d take',
    'VBZ': 'verb, 3rd person sing. present takes',
    'WDT': 'wh-determiner which',
    'WP': 'wh-pronoun who, what',
    'WP$': 'possessive wh-pronoun whose',
    'WRB': 'wh-abverb where, when'
}

nltk.data.path.append('/home/ressay/workspace/PFE_M2/app-backend/resources/')
DATA_TRAINING = json.load(open('resources/train_intents.json', 'r'))
INTENTS_SET = DATA_TRAINING['intents_set']
# TAGS_SET = DATA_TRAINING['tags_set']



POS2OH = create_postag_oh_dict(POSTAG_SET)
INTENT2OH = create_intent_oh_dict(INTENTS_SET)
TAG2OH = create_tag_oh_dict(TAGS_SET)
INDEX2INTENT = create_index_to_intent(INTENTS_SET)
INDEX2TAG = create_index_to_tag(TAGS_SET)

n_intents = len(INTENT2OH)
n_tags = len(TAG2OH)

vector_size = 300  # w2v_model.vector_size
postag_vec_size = len(POSTAG_SET)

conf_obj = {
        'activation': 'relu',
        'model_name': 'EncoderDecoder_BiLSTM_CPU_POSTAGS_PER_INTENT_',
        'encoder_input_dim': vector_size + postag_vec_size,
        'encoder_output_dim': 256,
        'encoder_dense_units': 512,
        'encoder_dense_output_dim': n_intents,
        'decoder_input_dim': n_tags,
        'decoder_output_dim': n_tags,
}

w2v_model = gensim.models.KeyedVectors.load_word2vec_format('models/GoogleNews-vectors-negative300.bin.gz',
                                                            binary=True, limit=1000000)
print('done with all the loadings')


def intent_tags_predict(text):
    model = EncoderDecoderCpuBiLSTM(conf_obj)
    model.load_models_weights('models/nlu_models/', 'base_20')
    # model.make_predict_functions()
    text = text.lower().split()
    word_vectors = [w2v(word, w2v_model) for word in text]
    postags = nltk.pos_tag(text)
    postags = [t for (w, t) in postags]
    word_postags_encoded = [POS2OH[w] for w in postags]

    x_train = np.array(
        [np.concatenate((vec, postag), axis=None) for vec, postag in zip(word_vectors, word_postags_encoded)],
        dtype='float32')
    x_train = np.reshape(x_train, newshape=(1, x_train.shape[0], x_train.shape[1]))
    tags, intent = model.predict_sequence(x_train, len(x_train[0]))
    tags_decoded = [INDEX2TAG[np.argmax(pred)] for pred in tags]
    intent_decoded = [INDEX2INTENT[np.argmax(intent[0])]]
    # pr(text)
    # pr(postags)
    return intent_decoded, tags_decoded, text


if __name__ == '__main__':
    intent, slots, text = intent_tags_predict('please open that file')
    print(intent)
    print(slots)
    print(text)
    pass

    # template_predict(model, w2v_model)
